# üé¨ TV Show Recommender System (LLM + MLOps)

### üöÄ Overview
This project is an **end-to-end intelligent TV Show Recommender System** built with modern GenAI, LLMs, and MLOps tools.  
It allows users to input their viewing preferences or show descriptions, and receive personalized TV show recommendations generated by an **LLM (Groq)** powered reasoning engine, supported by **semantic vector search**.

---

## üß† Tech Stack

| Layer | Tools / Frameworks | Description |
|-------|--------------------|-------------|
| **LLM & Language Framework** | [Groq API](https://groq.com/), [LangChain](https://python.langchain.com/) | Used Groq‚Äôs high-speed LLMs wrapped via LangChain for retrieval-augmented generation (RAG). |
| **Embeddings & Vector Store** | [Hugging Face Transformers](https://huggingface.co/), [Sentence-Transformers](https://www.sbert.net/), [ChromaDB](https://docs.trychroma.com/) | Used HF embedding models to generate text embeddings and stored them locally in ChromaDB for semantic retrieval. |
| **Data Source** | [TMDB Dataset](https://www.themoviedb.org/documentation/api) | Leveraged TMDB‚Äôs extensive movie/TV metadata for building the recommendation base. |
| **Application Framework** | [Streamlit](https://streamlit.io/) | Built an interactive web UI for entering user preferences and displaying recommendations. |
| **MLOps / Infrastructure** | [Docker](https://www.docker.com/), [Kubernetes (Minikube)](https://minikube.sigs.k8s.io/), [kubectl](https://kubernetes.io/docs/reference/kubectl/) | Containerized the app using Docker, deployed locally using Minikube for K8s orchestration, and interacted via kubectl. |
| **Version Control / CI** | [GitHub](https://github.com/) | Used for source code management and version control. |

---

## üß© Architecture

      +-------------------+
      |  Streamlit UI     |
      |  (User Input)     |
      +---------+---------+
                |
                v
      +---------+---------+
      | LangChain Pipeline |
      |  (Groq + Embeddings)|
      +---------+---------+
                |
                v
      +---------+---------+
      |  ChromaDB Vector  |
      |  Store (Semantic) |
      +---------+---------+
                |
                v
      +---------+---------+
      |  TMDB Data Source |
      +-------------------+


---

## ‚öôÔ∏è Workflow

1. **Data Preparation**  
   - Collected TV show metadata and descriptions using the TMDB API.  
   - Created vector embeddings using Sentence-Transformers from Hugging Face.

2. **Vector Store Setup**  
   - Stored embeddings in **ChromaDB**, enabling fast semantic retrieval.

3. **LLM Integration (Groq)**  
   - Integrated Groq via **LangChain**, enabling natural-language understanding and reasoning over retrieved content.

4. **Pipeline Building**  
   - Constructed a modular pipeline with retrieval + generation logic in LangChain.

5. **UI Development**  
   - Built a **Streamlit** interface for user input and recommendation visualization.

6. **Containerization and Deployment**  
   - Packaged the app with **Docker**.  
   - Deployed locally on **Kubernetes** using **Minikube** and managed via **kubectl** commands.

7. **Version Control and CI/CD**  
   - Managed the entire workflow via **GitHub**, ensuring code versioning and easy collaboration.

---

## üê≥ Docker & Kubernetes Deployment

```bash
# Build Docker image
docker build -t tvshow-recommender .

# Run locally
docker run -p 8501:8501 tvshow-recommender

# Deploy on Minikube
minikube start
kubectl apply -f deployment.yaml
kubectl apply -f service.yaml

# Get service URL
minikube service tvshow-recommender-service


üìö Learnings & Highlights

Implemented Retrieval-Augmented Generation (RAG) using Groq‚Äôs LLM and ChromaDB.

Gained deep understanding of LangChain‚Äôs modular components (prompt templates, retrievers, chains).

Integrated MLOps workflow with Docker & Kubernetes for scalable deployment.

Built a clean, intuitive Streamlit UI for real-time recommendations.

Learned DevOps practices (git workflows, remote pushing via SSH).

Understood the end-to-end pipeline from data ingestion ‚Üí vectorization ‚Üí semantic retrieval ‚Üí LLM reasoning ‚Üí UI visualization.


üßë‚Äçüíª Author

Akshay Sharma (AKAK555)
üìß gobusyakshay@gmail.com

üíº LinkedIn: www.linkedin.com/in/akshaye-sharrmaa-5b4035aa 

‚≠ê Contributions, suggestions, and forks are welcome!
